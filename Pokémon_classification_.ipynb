{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pok√©mon classification .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQbAOb/CMEG3bueHIutpKm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bement2050/Machine_learning_challenge/blob/main/Pok%C3%A9mon_classification_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#wget is used to download files from the servr \n",
        "pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6Emp5OLW7hU",
        "outputId": "6fde2ca3-5453-4ac2-9b5e-77405e2cd5ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=e45f82a11164a84148aa99508ca1769219e4824121b24522d4b00deea9c67531\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YEgrv6I5dJF1"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import tensorflow_hub as hub\n",
        "import wget\n",
        "from tensorflow.keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# There are 899 different types of pokemon the pokeapi website. Get requets are sent  retrivest the types by parsing the json file. \n"
      ],
      "metadata": {
        "id": "X_tm38S2SOyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# send get request and store types of the 899 pokemons\n",
        "ypes=[requests.get(\"https://pokeapi.co/api/v2/pokemon/{}\".format(i)).json()[\"types\"][0]['type']['name'] for i in list(range(1,899))]"
      ],
      "metadata": {
        "id": "q_at4jG0v1aH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grouping pokemons by type\n",
        "pd.Series(types).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AX1xy1IzyBH",
        "outputId": "49e78e56-4da5-437b-99af-237fc70c2e8b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "water       123\n",
              "normal      109\n",
              "grass        86\n",
              "bug          75\n",
              "fire         58\n",
              "psychic      58\n",
              "rock         50\n",
              "electric     49\n",
              "dark         36\n",
              "fighting     36\n",
              "poison       35\n",
              "ground       35\n",
              "dragon       31\n",
              "ghost        31\n",
              "steel        30\n",
              "ice          28\n",
              "fairy        21\n",
              "flying        7\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For this problem I am going to use their front default image to classify their type\n",
        "# send a get request to the api and retrive Urls for the front default picture  of each pokemon\n",
        "images=[requests.get(\"https://pokeapi.co/api/v2/pokemon/{}\".format(i)).json()['sprites']['front_default'] for i in list(range(1,899))]"
      ],
      "metadata": {
        "id": "InhbxgqV0HVP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe with two columns  \n",
        "dataset1=pd.DataFrame({'images':images,'type':types})"
      ],
      "metadata": {
        "id": "FCVhC4CF7_GR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ELVXQs6kbTMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#makes a directory to store the images\n",
        "os.mkdir('dataset')"
      ],
      "metadata": {
        "id": "eKflTCItOR0-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creates subdirectories for each unique type under dataset\n",
        "for x in dataset1['type'].unique():\n",
        "  os.mkdir('dataset/{}'.format(x))"
      ],
      "metadata": {
        "id": "33QNbcdpLKNB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Goes through each pokmen on saves the image in to respective directory \n",
        "for k in range(len(dataset1)):\n",
        "  wget.download(dataset1.loc[k]['images'],\"dataset/{}\".format(dataset1.loc[k]['type']))"
      ],
      "metadata": {
        "id": "zhJX67ZqPuZo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define some parameters for the loader:\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "img_height =255\n",
        "img_width = 255"
      ],
      "metadata": {
        "id": "MJQ_cYX9ioKq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load these images off disk using the helpful tf.keras.utils.image_dataset_from_directory utility. This will take us  \n",
        "# from a directory of images on disk to a tf.data.Dataset\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  '/content/dataset',\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C2tQIyciyN2",
        "outputId": "390b4654-db76-4368-b677-991d0296ecc4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 898 files belonging to 18 classes.\n",
            "Using 719 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  '/content/dataset',\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHHfEbm8i640",
        "outputId": "8520683d-d1a3-41e3-db6c-7d16fba7b0ab"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 898 files belonging to 18 classes.\n",
            "Using 179 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can find the class names in the class_names attribute on these datasets. These correspond to the directory names \n",
        "# in alphabetical order.\n",
        "type_names=train_ds.class_names"
      ],
      "metadata": {
        "id": "sXieEQfBjHoR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzyIM_vNjPrQ",
        "outputId": "7c0df25b-cd75-45d4-ce9c-5dfb0863ffe3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bug',\n",
              " 'dark',\n",
              " 'dragon',\n",
              " 'electric',\n",
              " 'fairy',\n",
              " 'fighting',\n",
              " 'fire',\n",
              " 'flying',\n",
              " 'ghost',\n",
              " 'grass',\n",
              " 'ground',\n",
              " 'ice',\n",
              " 'normal',\n",
              " 'poison',\n",
              " 'psychic',\n",
              " 'rock',\n",
              " 'steel',\n",
              " 'water']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1CSQJEkjRY4",
        "outputId": "6556a803-f896-4c4d-926c-5fbe4bb73f7c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 255, 255, 3)\n",
            "(10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using buffered prefetching so we can yield data from disk without having I/O become blocking.\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "WBth2YU7jfCj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# standardizing pixel values between 0 and 1\n",
        "normalization_layer = layers.Rescaling(1./255)"
      ],
      "metadata": {
        "id": "ZEfUWqj8jfk5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# making pixel values between[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hG_304sjh2q",
        "outputId": "3615e1b1-01c7-424e-e11f-e89c5f66a48a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(type_names)"
      ],
      "metadata": {
        "id": "EXeNRblm3aQu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\",\n",
        "                      input_shape=(img_height,\n",
        "                                  img_width,\n",
        "                                  3)),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "k0CnSZu2kkyD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "AvX_i5ICkqjI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-JXwYkkTkvJ5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUahRc40kxBl",
        "outputId": "2cdfd257-a3a4-4c29-c2d2-49ef1d685908"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 255, 255, 3)       0         \n",
            "                                                                 \n",
            " rescaling_1 (Rescaling)     (None, 255, 255, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 255, 255, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 127, 127, 16)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 127, 127, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 63, 63, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 63, 63, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 31, 31, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 31, 31, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 61504)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               7872640   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 18)                2322      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,898,546\n",
            "Trainable params: 7,898,546\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2VaOLOlkyTL",
        "outputId": "6b925c17-687c-4337-cada-0ebda98ebdbb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "72/72 [==============================] - 55s 742ms/step - loss: 2.8326 - accuracy: 0.1280 - val_loss: 2.6711 - val_accuracy: 0.1676\n",
            "Epoch 2/15\n",
            "72/72 [==============================] - 52s 724ms/step - loss: 2.6140 - accuracy: 0.2197 - val_loss: 2.5910 - val_accuracy: 0.2458\n",
            "Epoch 3/15\n",
            "72/72 [==============================] - 52s 726ms/step - loss: 2.5122 - accuracy: 0.2267 - val_loss: 2.5780 - val_accuracy: 0.2570\n",
            "Epoch 4/15\n",
            "72/72 [==============================] - 52s 721ms/step - loss: 2.4349 - accuracy: 0.2740 - val_loss: 2.5395 - val_accuracy: 0.2402\n",
            "Epoch 5/15\n",
            "72/72 [==============================] - 52s 721ms/step - loss: 2.3639 - accuracy: 0.2851 - val_loss: 2.4966 - val_accuracy: 0.2793\n",
            "Epoch 6/15\n",
            "72/72 [==============================] - 52s 726ms/step - loss: 2.3314 - accuracy: 0.3046 - val_loss: 2.5361 - val_accuracy: 0.2179\n",
            "Epoch 7/15\n",
            "72/72 [==============================] - 52s 725ms/step - loss: 2.2349 - accuracy: 0.3171 - val_loss: 2.5603 - val_accuracy: 0.2961\n",
            "Epoch 8/15\n",
            "72/72 [==============================] - 53s 736ms/step - loss: 2.2705 - accuracy: 0.3171 - val_loss: 2.5957 - val_accuracy: 0.2346\n",
            "Epoch 9/15\n",
            "72/72 [==============================] - 54s 747ms/step - loss: 2.1646 - accuracy: 0.3408 - val_loss: 2.5724 - val_accuracy: 0.2626\n",
            "Epoch 10/15\n",
            "72/72 [==============================] - 56s 779ms/step - loss: 2.1768 - accuracy: 0.3241 - val_loss: 2.6145 - val_accuracy: 0.2346\n",
            "Epoch 11/15\n",
            "72/72 [==============================] - 56s 779ms/step - loss: 2.0784 - accuracy: 0.3477 - val_loss: 2.5888 - val_accuracy: 0.2849\n",
            "Epoch 12/15\n",
            "72/72 [==============================] - 57s 796ms/step - loss: 2.0182 - accuracy: 0.3700 - val_loss: 2.6840 - val_accuracy: 0.2849\n",
            "Epoch 13/15\n",
            "72/72 [==============================] - 55s 770ms/step - loss: 1.9575 - accuracy: 0.3978 - val_loss: 2.6737 - val_accuracy: 0.2793\n",
            "Epoch 14/15\n",
            "72/72 [==============================] - 52s 726ms/step - loss: 1.9506 - accuracy: 0.3811 - val_loss: 2.7791 - val_accuracy: 0.2011\n",
            "Epoch 15/15\n",
            "72/72 [==============================] - 52s 726ms/step - loss: 1.8731 - accuracy: 0.4089 - val_loss: 2.8851 - val_accuracy: 0.2570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we got accuracy of 40% on the training set and 25 % on the validation , It is not bad considering we only have few dataset and\n",
        "# so many classes "
      ],
      "metadata": {
        "id": "lcxept5_UzR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding final layer to change the prediction to probability\n",
        "probability_model = tf.keras.Sequential([model, \n",
        "                                         tf.keras.layers.Softmax()])"
      ],
      "metadata": {
        "id": "AVx4sl8tNkLT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probability_model.save('mymodel.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkvznrS4Rg34",
        "outputId": "e820047a-3948-4457-84cb-83cb14a01cdc"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probability_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmZu0uUFRgwA",
        "outputId": "92f6f289-afb4-4239-ce14-8d4b1d9e91b6"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_1 (Sequential)   (None, 18)                7898546   \n",
            "                                                                 \n",
            " softmax (Softmax)           (None, 18)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,898,546\n",
            "Trainable params: 7,898,546\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2=load_model('mymodel.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "AJT8w-rfRgsF",
        "outputId": "3365231a-fc03-4a6c-af73-2d520dffe5c9"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-03983b8979fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mymodel.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'No file or directory found at {filepath}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_hdf5_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             raise ImportError(\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at mymodel.h5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6XPdCxjRgmV",
        "outputId": "3aa27c04-1907-43ea-c60d-5b3a806839ee"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_4 (Sequential)   (None, 18)                7898546   \n",
            "                                                                 \n",
            " softmax_1 (Softmax)         (None, 18)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,898,546\n",
            "Trainable params: 7,898,546\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to process input . It takes json input ( dict) and outputs  array \n",
        "def process(inputs):\n",
        "  url=inputs['sprites']['front_default']\n",
        "  url_path = tf.keras.utils.get_file( origin=url)\n",
        "  img = tf.keras.utils.load_img(url_path, target_size=(img_height, img_width))\n",
        "  img_array = tf.keras.utils.img_to_array(img)\n",
        "  img_array = tf.expand_dims(img_array, 0)\n",
        "  return img_array\n",
        "# following function takes image as an array and predicts  the type .\n",
        "def predict(Processed_input):\n",
        "  predictions = model.predict(Processed_input)\n",
        "  score = tf.nn.softmax(predictions[0])\n",
        "  return (type_names[np.argmax(score)])\n"
      ],
      "metadata": {
        "id": "Vji8ablZyKYS"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fH1g2ZD6tCbh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example"
      ],
      "metadata": {
        "id": "LW2H4olEGXU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4pIps2aJab7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the data from PokeAPI\n",
        "resp = requests.get(\"https://pokeapi.co/api/v2/pokemon/kingdra\").json()"
      ],
      "metadata": {
        "id": "9BHRdyuXYdGH"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_resp=process(resp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIsiHRpwWBPV",
        "outputId": "aeed8167-3409-4373-c7ef-446f08ce4572"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/PokeAPI/sprites/master/sprites/pokemon/230.png\n",
            "\r16384/816 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(processed_resp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uLaKg3-VWgc2",
        "outputId": "3aff48d2-d211-4bdf-e6f2-8205e3666e2b"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'water'"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gaWc3OIRplsn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}